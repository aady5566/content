# 課程模組：GenAI 驅動的強化學習實戰 (RL via Gemini)
**副標題：從零打造會自我進化的遊戲 AI**
* **核心工具**：Google Gemini (LLM), HTML5/JavaScript (Zero-Install)

---

## 1. 課程核心目標 (Goal)
**Prompt Engineering (提示詞工程)** 與 Gemini 協作，在不需深厚數學背景下實作 **Q-Learning** 演算法。學生將親眼見證 AI 從「隨機亂試」到「掌握策略」的過程，體驗 DeepMind 開發 AlphaGo/Atari AI 的核心精神。

---

## 2. 課程暖身：靈感與啟發 (The Inspiration)

**教材素材**：DeepMind 紀錄片《The Thinking Game》
**關鍵片段**：`00:09:00` - `00:12:30` (Atari 遊戲訓練展示)

* **觀察重點**：
    1.  **隨機期**：一開始 AI (DQN) 控制的板子像無頭蒼蠅一樣亂動。
    2.  **頓悟期**：經過幾百局後，AI 發現「只要接到球就能得分」。
    3.  **精通期 (挖隧道)**：AI 發現了人類都沒想到的策略——把球打到磚塊後方，讓球自動反彈消除磚塊。
* **核心觀念引導**：
    > "We didn't build it to play any of them... it learned from its own experience."
    > (我們沒有教它規則，它是從經驗中學習的。)

---

## 3. 觀念解說：白話文 Q-Learning (The Concept)

**(建議搭配板書或投影片)**

### 3.1 什麼是 Q-Learning？(作弊小抄理論)
想像你明天要考一門超難的考試，但老師允許你帶一張 **「全能作弊小抄」(Q-Table)** 進去。
Q-Learning 就是 AI 透過不斷嘗試，**由空白開始填寫這張小抄**的過程。

* **小抄的結構**：
    * **橫列 (Row)** = **狀態 (State)**：你現在看到的題目（例如：球在左邊）。
    * **直欄 (Column)** = **動作 (Action)**：你可以做的選擇（例如：往左移、往右移）。
    * **格子裡的數字** = **Q 值 (Quality)**：選這個答案大概能拿幾分。

### 3.2 AI 的學習兩階段
1.  **亂猜時期 (Exploration / 探索)**：
    * AI 遇到題目，它不知道答案，於是**丟骰子**隨便選一個動作。
    * **結果**：如果接到球（+10分），它趕快在小抄上記錄：「這招有效！」。
2.  **老鳥時期 (Exploitation / 利用)**：
    * 玩了幾千次後，小抄寫滿了。AI 看到題目，直接查表選分數最高的動作。

### 3.3 核心公式 (白話版)
$$NewQ = OldQ + 學習率 \times (真實獎勵 + 對未來的預期 - OldQ)$$

> **翻譯**：「我原本以為這家餐廳只有 50 分。今天去吃發現超好吃 (+10分)，而且聽說隔壁桌還有隱藏甜點 (+未來預期)。所以，我要修正這家餐廳的評價，把它調高一點點！」

---

## 4. 課堂實作：打造「接寶物 AI」 (Lab Session)

**目標**：使用 Gemini 生成一個單一 HTML 檔案的遊戲，並包含「手動/AI 切換」功能。

### 4.1 提示詞工程 (Prompt Engineering)
請學生（或講師演示）將以下 Prompt 輸入給 Gemini：

> **Prompt 範例**：
> 請扮演資深 Web 遊戲工程師。我要製作一個單一檔案的 HTML5 遊戲，演示強化學習 (RL)。
>
> **1. 遊戲基礎:**
> * **類型**: 接寶物 (Catch the falling object)。
> * **操作**: 支援「觸控滑動/滑鼠跟隨」，手指在哪板子就在哪。
> * **規則**: 接到 +10 分，漏接 -10 分。
>
> **2. AI 核心 (Q-Learning):**
> * **狀態 (State)**: 簡化為「Target 與 Player 的水平距離區間」(分 10 格)。不要用像素。
> * **動作**: 左移、右移、不動。
> * **機制**: 實作 Q-Learning 演算法與 Epsilon-Greedy 策略。
>
> **3. 介面功能 (UI):**
> * **切換開關**: [手動模式] (綠色) / [AI 模式] (藍色)。
> * **加速按鈕**: 在 AI 模式下，提供「極速訓練 (Fast Train)」按鈕，關閉渲染快轉 2000 回合。
> * **儀表板**: 顯示分數、回合數、探索率 (Epsilon)。
>
> 請給我完整的 HTML 程式碼。

### 4.2 完整程式碼範例 (Catch Game Code)
**請參考：[w13-game-inclass-demo.html](../1141-gk2362k24/gen_stuff/w13-game-inclass-demo.html)**

### 5. 課後作業：Project Alpha-Breakout (Homework)
作業說明：利用今天學到的 Q-Learning 原理，製作一個「打磚塊」遊戲。不僅要讓 AI 會玩，遊戲本身也要具備良好的互動手感與聲光效果。

#### 5.1 評分權重 (Evaluation Criteria)
本次作業將依據以下三大面向進行評分：

1. 核心功能與物理機制 (40%)

物理反彈：球撞到牆壁、板子、磚塊時，反彈角度是否自然？（例如：撞到板子邊緣反彈角度較大）。

操作流暢度：手動模式下，手指/滑鼠拖曳板子是否跟手？不會有延遲或卡頓。

遊戲循環：具備完整的「重置 (Reset)」功能，死掉或過關後能重新開始。

2. AI 智能實作 (40%)

Q-Learning 機制：是否正確實作 Q 表更新公式。

訓練成效：提供「加速訓練」功能，且訓練 2000-3000 回合後，AI 必須能穩定接球（存活率 > 80%）。

狀態定義：Prompt 是否引導 Gemini 考量「球的飛行方向」，而不僅僅是位置（這是 AI 能否學會接反彈球的關鍵）。

3. 創意與延伸功能 (20%)

視覺回饋 (Juice)：例如打掉磚塊時有粒子特效、畫面震動，或板子顏色的變化。

關卡設計：例如打完一波磚塊後，會進入 Level 2（球速變快或磚塊排列改變）。

音效 (選用)：若行有餘力，可嘗試加入簡單的 Web Audio API 音效。

5.2 給學生的 Prompt 指導建議
請依照以下結構引導 Gemini，特別強調第三點的「特效」：

1. 任務: 製作 HTML5 打磚塊遊戲，內建 Q-Learning AI。 2. 物理要求: 球要有合理的反彈物理，板子跟隨滑鼠/手指移動。 3. AI 要求: State 必須包含「球的位置」與「球的速度方向」。要有 Fast Train 按鈕。 4. 視覺優化 (Bonus):

請加入「粒子系統 (Particle System)」，當磚塊被打破時，產生爆炸碎片效果。

請加入「關卡機制」，清空磚塊後進入下一關，球速變快。

